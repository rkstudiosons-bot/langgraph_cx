{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f934e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c64a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the object of GEMINI Model \n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02106bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It learns patterns from data to make predictions and decisions.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "# Define a node that calls Gemini\n",
    "def gemini_node(state: State) -> State:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=state[\"question\"]\n",
    "    )\n",
    "    state[\"answer\"] = response.text\n",
    "    return state\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"gemini\", gemini_node)\n",
    "workflow.set_entry_point(\"gemini\")\n",
    "workflow.add_edge(\"gemini\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test it\n",
    "result = app.invoke({\"question\": \"Explain how AI works in a few words\", \"answer\": \"\"})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bca9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_node(state: LLMState) -> LLMState:\n",
    "\n",
    "    #extract the question from the state\n",
    "    question = state['question']\n",
    "\n",
    "    #form a prompt\n",
    "    prompt = f\"Please answer the following question: {question}\"\n",
    "\n",
    "    # ask that question to the LLM\n",
    "    response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\", \n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "    #Update the answer in the state\n",
    "    state[\"answer\"] = response.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2560b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a State\n",
    "class LLMState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f6238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) isn't a single technology but a broad field focused on enabling machines to perform tasks that typically require human intelligence. At its core, AI works by **processing vast amounts of data, identifying patterns, learning from those patterns, and then making predictions or decisions based on what it has learned.**\n",
      "\n",
      "Let's break down the detailed mechanics:\n",
      "\n",
      "## I. The Fundamental Pillars of AI\n",
      "\n",
      "1.  **Data:** This is the fuel of AI. AI systems learn from data, and the quality, quantity, and relevance of this data are paramount. Data can be structured (databases, spreadsheets) or unstructured (text, images, audio, video).\n",
      "2.  **Algorithms:** These are the sets of rules and instructions that an AI system follows to process data, identify patterns, and learn. Different tasks require different algorithms.\n",
      "3.  **Computational Power:** Modern AI, especially deep learning, requires significant processing power (CPUs, and more importantly, GPUs or TPUs) to handle large datasets and complex algorithms.\n",
      "\n",
      "## II. The Core Paradigms of How AI Learns and Works\n",
      "\n",
      "The vast majority of modern AI (especially the kind we interact with daily) operates through **Machine Learning (ML)**, a subset of AI.\n",
      "\n",
      "### A. Machine Learning (ML)\n",
      "\n",
      "Machine Learning is about creating systems that can learn from data without being explicitly programmed for every specific task. Instead of writing rules for every possible scenario, you give the system data and an algorithm, and it \"learns\" the rules itself.\n",
      "\n",
      "There are three main types of Machine Learning:\n",
      "\n",
      "1.  **Supervised Learning:**\n",
      "    *   **How it works:** The AI is trained on a dataset that is \"labeled,\" meaning each input has a corresponding correct output. The system learns to map inputs to outputs.\n",
      "    *   **Process:**\n",
      "        *   **Data Input:** You feed the algorithm input data (features) and the correct output (labels). For example, images of cats and dogs, with each image explicitly labeled \"cat\" or \"dog.\"\n",
      "        *   **Model Training:** The algorithm analyzes the data, tries to find relationships between the features and the labels, and builds a \"model.\" This involves adjusting internal parameters (weights and biases) to minimize the error between its predictions and the actual labels.\n",
      "        *   **Prediction/Inference:** Once trained, the model can take new, unlabeled input data and predict the most likely output.\n",
      "    *   **Common Tasks:**\n",
      "        *   **Classification:** Categorizing input into one of several classes (e.g., spam/not spam, disease/no disease, recognizing objects in an image).\n",
      "        *   **Regression:** Predicting a continuous numerical value (e.g., house prices based on features, stock market prediction, temperature forecasting).\n",
      "    *   **Algorithms:** Linear Regression, Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Random Forests, Gradient Boosting (XGBoost, LightGBM).\n",
      "\n",
      "2.  **Unsupervised Learning:**\n",
      "    *   **How it works:** The AI is given unlabeled data and is tasked with finding hidden patterns, structures, or relationships within that data on its own. It's like finding order in chaos.\n",
      "    *   **Process:**\n",
      "        *   **Data Input:** Unlabeled data is fed into the algorithm.\n",
      "        *   **Pattern Discovery:** The algorithm autonomously identifies inherent structures, groupings, or dimensions within the data.\n",
      "        *   **Output:** The output is typically a categorization or a reduced representation of the data based on these discovered patterns.\n",
      "    *   **Common Tasks:**\n",
      "        *   **Clustering:** Grouping similar data points together (e.g., segmenting customers into different market groups, organizing news articles by topic).\n",
      "        *   **Dimensionality Reduction:** Reducing the number of features in a dataset while retaining most of the important information (e.g., principal component analysis for data visualization and efficiency).\n",
      "        *   **Association Rule Mining:** Discovering rules that describe relationships between variables (e.g., \"customers who buy bread also tend to buy milk\").\n",
      "    *   **Algorithms:** K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), Independent Component Analysis (ICA).\n",
      "\n",
      "3.  **Reinforcement Learning (RL):**\n",
      "    *   **How it works:** An AI \"agent\" learns by interacting with an \"environment.\" It performs actions, receives \"rewards\" (or penalties) based on the outcome of those actions, and tries to learn a \"policy\" that maximizes its cumulative reward over time. It's like training a dog with treats.\n",
      "    *   **Process:**\n",
      "        *   **Agent & Environment:** An agent exists within an environment.\n",
      "        *   **State:** The agent observes the current state of the environment.\n",
      "        *   **Action:** Based on the state, the agent chooses an action.\n",
      "        *   **Reward:** The environment provides a reward (positive or negative) for the action taken.\n",
      "        *   **New State:** The environment transitions to a new state.\n",
      "        *   **Learning:** The agent updates its \"policy\" (its strategy for choosing actions) to favor actions that lead to higher rewards.\n",
      "    *   **Common Tasks:**\n",
      "        *   **Game Playing:** Mastering complex games (e.g., AlphaGo, chess engines).\n",
      "        *   **Robotics:** Teaching robots to perform tasks in the real world (e.g., walking, gripping objects).\n",
      "        *   **Autonomous Driving:** Training self-driving cars to navigate.\n",
      "        *   **Resource Management:** Optimizing energy consumption in data centers.\n",
      "    *   **Algorithms:** Q-Learning, SARSA, Deep Q Networks (DQN), Proximal Policy Optimization (PPO), A2C.\n",
      "\n",
      "### B. Deep Learning (DL) - A Subset of Machine Learning\n",
      "\n",
      "Deep Learning is a specialized subfield of Machine Learning that uses **Artificial Neural Networks (ANNs)** with multiple layers (hence \"deep\") to learn complex patterns. It's particularly powerful for handling highly complex, unstructured data like images, audio, and natural language.\n",
      "\n",
      "1.  **Artificial Neural Networks (ANNs):**\n",
      "    *   **Inspired by the Brain:** ANNs are loosely modeled on the human brain's structure, composed of interconnected \"neurons\" (nodes).\n",
      "    *   **Structure:**\n",
      "        *   **Input Layer:** Receives the raw data.\n",
      "        *   **Hidden Layers:** One or more layers between the input and output. Each neuron in a hidden layer performs computations on the inputs it receives from the previous layer. The \"depth\" of the network refers to the number of hidden layers.\n",
      "        *   **Output Layer:** Produces the final prediction or classification.\n",
      "    *   **How a Neuron Works:** Each connection between neurons has a numerical \"weight\" and a \"bias.\" When data flows through the network:\n",
      "        1.  Each neuron receives inputs from the previous layer.\n",
      "        2.  It multiplies each input by its corresponding weight, sums these products, and adds a bias.\n",
      "        3.  It then passes this sum through an \"activation function\" (e.g., ReLU, Sigmoid, Tanh) which introduces non-linearity, allowing the network to learn complex relationships.\n",
      "    *   **Learning (Backpropagation & Gradient Descent):**\n",
      "        1.  **Forward Pass:** Input data moves from the input layer through the hidden layers to the output layer, producing a prediction.\n",
      "        2.  **Loss Function:** A \"loss function\" (or cost function) measures how far off the prediction is from the actual correct output (for supervised learning).\n",
      "        3.  **Backpropagation:** The error is propagated backward through the network. This process calculates how much each weight and bias contributed to the error.\n",
      "        4.  **Gradient Descent:** An optimization algorithm (like Gradient Descent or its variants like Adam) uses these error calculations to slightly adjust the weights and biases in the direction that minimizes the loss function. This iterative process is how the network learns.\n",
      "\n",
      "2.  **Key Deep Learning Architectures:**\n",
      "    *   **Convolutional Neural Networks (CNNs):** Excellent for image and video processing. They use \"convolutional layers\" to automatically detect features (edges, textures, shapes) from raw pixel data. Used in facial recognition, object detection, medical imaging.\n",
      "    *   **Recurrent Neural Networks (RNNs) / LSTMs / GRUs:** Designed for sequential data (time series, text, speech). They have \"memory\" that allows information to persist across steps in the sequence. Used in natural language processing (translation, speech recognition), stock prediction. LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units) are more advanced variants that address the vanishing gradient problem in vanilla RNNs.\n",
      "    *   **Transformers:** Revolutionized NLP. They use an \"attention mechanism\" to weigh the importance of different parts of the input sequence when making predictions, allowing for highly parallel processing and capturing long-range dependencies more effectively than RNNs. They are the backbone of large language models (LLMs) like GPT-3/4, BERT, T5.\n",
      "    *   **Generative Adversarial Networks (GANs):** Composed of two neural networks (a Generator and a Discriminator) that compete. The Generator creates new data (e.g., fake images), and the Discriminator tries to distinguish between real and generated data. This adversarial process leads to highly realistic generated content.\n",
      "    *   **Variational Autoencoders (VAEs) and Diffusion Models:** Other generative models capable of creating new data, particularly prominent in modern image and video generation.\n",
      "\n",
      "## III. Other AI Paradigms (Less Dominant in Modern AI but Historically Important)\n",
      "\n",
      "*   **Symbolic AI (Good Old-Fashioned AI - GOFAI):**\n",
      "    *   **How it works:** Relies on human-coded rules, logic, and knowledge representation (e.g., \"If X, then Y\" statements). It attempts to model human reasoning directly using symbols.\n",
      "    *   **Examples:** Expert Systems (e.g., medical diagnosis systems where doctors' knowledge is codified into rules), knowledge graphs.\n",
      "    *   **Limitations:** Struggles with ambiguity, large amounts of data, and situations where rules are not easily defined (e.g., recognizing a cat in an image).\n",
      "\n",
      "*   **Evolutionary Computation:**\n",
      "    *   **How it works:** Inspired by biological evolution (natural selection, mutation, crossover). Algorithms like Genetic Algorithms try to find optimal solutions by evolving a population of candidate solutions.\n",
      "    *   **Examples:** Optimization problems, robot design.\n",
      "\n",
      "## IV. From Learning to Application: Key Capabilities\n",
      "\n",
      "Once trained, these underlying mechanisms power various AI capabilities:\n",
      "\n",
      "*   **Natural Language Processing (NLP):** Understanding, interpreting, and generating human language. This involves tasks like text classification, sentiment analysis, machine translation, chatbots, and large language models (LLMs).\n",
      "*   **Computer Vision (CV):** Enabling machines to \"see\" and interpret visual information from images and videos. This includes object detection, facial recognition, image classification, and self-driving car perception.\n",
      "*   **Speech Recognition:** Converting spoken language into text.\n",
      "*   **Recommendation Systems:** Predicting user preferences to suggest products, movies, music, etc. (e.g., Netflix, Amazon).\n",
      "*   **Robotics:** Integrating AI with physical robots to enable autonomous navigation, manipulation, and interaction with the environment.\n",
      "*   **Generative AI:** Creating entirely new and original content (text, images, music, video) that is realistic and often indistinguishable from human-created content.\n",
      "\n",
      "## V. The AI Workflow (Simplified)\n",
      "\n",
      "1.  **Problem Definition:** Clearly define the task AI needs to solve.\n",
      "2.  **Data Collection & Preprocessing:** Gather relevant data, clean it, handle missing values, normalize it, and potentially label it. This is often the most time-consuming step.\n",
      "3.  **Feature Engineering (Traditional ML) / Feature Learning (Deep Learning):**\n",
      "    *   **ML:** Manually selecting or transforming raw data into \"features\" that the algorithm can better understand.\n",
      "    *   **DL:** Neural networks can often learn relevant features automatically from raw data.\n",
      "4.  **Model Selection:** Choose an appropriate algorithm or neural network architecture based on the problem and data type.\n",
      "5.  **Model Training:** Feed the processed data to the chosen algorithm, allowing it to learn patterns and adjust its internal parameters (weights, biases).\n",
      "6.  **Model Evaluation:** Test the trained model on unseen data to assess its performance (accuracy, precision, recall, F1-score, etc.). Identify issues like overfitting (memorizing training data) or underfitting (not learning enough).\n",
      "7.  **Hyperparameter Tuning:** Adjust the parameters of the learning algorithm itself (not the model's internal weights) to optimize performance.\n",
      "8.  **Deployment & Monitoring:** Integrate the trained model into an application or system, make it available for predictions (\"inference\"), and continuously monitor its performance in the real world.\n",
      "\n",
      "In summary, AI works by enabling machines to learn from data, identify complex patterns through various algorithms (predominantly machine learning and deep learning), and then apply that learned knowledge to make intelligent decisions or perform specific tasks, mimicking aspects of human cognition.\n"
     ]
    }
   ],
   "source": [
    "#create a graph\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "# Add you nodes\n",
    "graph.add_node(\"gemini\", gemini_node)\n",
    "\n",
    "# add your edges\n",
    "graph.add_edge(START, \"gemini\")\n",
    "graph.add_edge(\"gemini\", END)\n",
    "\n",
    "#compile the graph\n",
    "workflow = graph.compile()\n",
    "\n",
    "#execute the graph\n",
    "initial_state = {\"question\": \"Explain how AI works in detailed\", \"answer\": \"\"}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929906c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-cx (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
