{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bcfb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Literal, NotRequired\n",
    "from pydantic import BaseModel, Field\n",
    "from google import genai\n",
    "import os\n",
    "from google.genai.types import GenerateContentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf30be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76636232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Did .env file load? -> True\n",
      "2. Is api_key variable found? -> True\n",
      "3. Key starts with: AIza...\n",
      "4. Key length: 39\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "\n",
    "# 1. Load the environment variables\n",
    "loaded = load_dotenv()\n",
    "\n",
    "# 2. Get the key\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # Make sure this name matches your .env file exactly\n",
    "\n",
    "print(f\"1. Did .env file load? -> {loaded}\")\n",
    "print(f\"2. Is api_key variable found? -> {api_key is not None}\")\n",
    "\n",
    "if api_key:\n",
    "    # Print only the first 4 characters for safety\n",
    "    print(f\"3. Key starts with: {api_key[:4]}...\")\n",
    "    print(f\"4. Key length: {len(api_key)}\")\n",
    "else:\n",
    "    print(\"3. RESULT: The code cannot read the variable. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd234830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description=\"The overall sentiment of the text.\")\n",
    "\n",
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description=\"List of identified issues in the review.\")\n",
    "    tone: Literal[\"neutral\", \"angry\", \"frustrated\", \"sad\", \"disappointed\", \"calm\"] = Field(description=\"The tone of the review.\")\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"The urgency and critical level of the review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "287536af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Error: GEMINI_API_KEY is missing from .env file.\")\n",
    "\n",
    "# 3. CRITICAL FIX: Initialize Client with the key here\n",
    "# Do NOT rely on automatic detection if it is failing.\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "schema = SentimentSchema.model_json_schema()\n",
    "\n",
    "#parsing\n",
    "config = GenerateContentConfig(\n",
    "    response_mime_type=\"application/json\",\n",
    "    response_schema=schema\n",
    ")\n",
    "\n",
    "# Use \"gemini-1.5-flash\" or \"gemini-2.0-flash-exp\"\n",
    "try:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=\"What is the sentiment of the following reviews - Software is too good.\",\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # 5. Validate and print\n",
    "    result = SentimentSchema.model_validate_json(response.text)\n",
    "    print(f\"Sentiment: {result.sentiment}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f289f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NotRequired\n",
    "\n",
    "class ReviewState(TypedDict):\n",
    "    review_text: str\n",
    "    sentiment: NotRequired[Literal[\"positive\", \"negative\"]]\n",
    "    diagnosis: NotRequired[dict]\n",
    "    response: NotRequired[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f5cb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState) -> ReviewState:\n",
    "    # 3. CRITICAL FIX: Initialize Client with the key here\n",
    "    prompt = f\"For the followoing review find out the sentiment \\n {state['review_text'] }\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=prompt,\n",
    "        config=config\n",
    "    )\n",
    "    result = SentimentSchema.model_validate_json(response.text)\n",
    "    return {'sentiment': result.sentiment}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditional workflow graph\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "    sentiment = state.get('sentiment', '')\n",
    "    if sentiment == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6a79f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state: ReviewState) -> ReviewState:\n",
    "    prompt = f\"Write a warm thank you reply to the following positive review:\\n\\n {state['review_text']}. \\n Also ask user to leave feedback on our website.\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=prompt\n",
    "    )\n",
    "    result = response.text\n",
    "    return {'response': result}\n",
    "\n",
    "\n",
    "def run_diagnosis(state: ReviewState) -> ReviewState:\n",
    "    # Create config for DiagnosisSchema\n",
    "    diagnosis_schema = DiagnosisSchema.model_json_schema()\n",
    "    diagnosis_config = GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=diagnosis_schema\n",
    "    )\n",
    "    \n",
    "    prompt = f\"Diagnose the issues in the following negative review and suggest improvements:\\n\\n {state['review_text']}. \\n Return issue_type, tone and urgency.\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=prompt,\n",
    "        config=diagnosis_config\n",
    "    )\n",
    "    result = DiagnosisSchema.model_validate_json(response.text)\n",
    "    return {'diagnosis': result.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState) -> ReviewState:\n",
    "    diagnosis = state.get('diagnosis', {})\n",
    "    prompt = f\"Write a professional empathetic reply to the following negative review addressing {diagnosis.get('issue_type', 'the issues')} with a {diagnosis.get('tone', 'professional')} tone.\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        contents=prompt\n",
    "    )\n",
    "    result = response.text\n",
    "    return {'response': result}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bf3ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_text': 'The software is pathetic and crashes all the time. Customer support was unhelpful and rude.', 'sentiment': 'negative', 'diagnosis': {'issue_type': 'Bug', 'tone': 'angry', 'urgency': 'high'}, 'response': 'Dear [Customer\\'s Name, if known, otherwise \"Valued Customer\" or \"Reviewer\"],\\n\\nThank you for taking the time to share your feedback. I am truly sorry to hear about the frustration and anger you\\'re experiencing with the bug you\\'ve encountered. We understand how incredibly upsetting it can be when our product doesn\\'t perform as expected, and for that, please accept our sincerest apologies.\\n\\nThis is certainly not the experience we want any of our users to have, and we are very concerned to learn about this issue. We take bug reports seriously, and your detailed feedback is invaluable in helping us identify and fix problems to improve our service for everyone.\\n\\nOur development team has been alerted and is actively investigating reports like yours with the highest priority. To help us get to the bottom of this specific issue as quickly as possible, we would be incredibly grateful if you could provide more details directly to our support team.\\n\\nPlease reach out to us at [Support Email Address] or call us at [Support Phone Number] at your earliest convenience. If you can include information such as [e.g., your account ID, device type, operating system, specific steps to reproduce the bug, or any error messages you received], it would greatly assist us in diagnosing and resolving the problem swiftly.\\n\\nYour satisfaction is incredibly important to us, and we are committed to resolving this issue for you and ensuring a smoother, more reliable experience going forward. We truly appreciate your patience and cooperation as we work to make things right.\\n\\nSincerely,\\n\\nThe [Your Company Name] Team'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "graph.add_edge('positive_response', END)\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "initial_state = {\n",
    "    'review_text': \"The software is pathetic and crashes all the time. Customer support was unhelpful and rude.\"\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c74f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-cx (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
